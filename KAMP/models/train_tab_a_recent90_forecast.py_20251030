"""
íŒŒì¼ëª… : train_tab_a_recent90_forecast.py
ì„¤ëª…   : Product_Numberë³„ ìµœê·¼ 90ì¼ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 7ì¼ì¹˜(Tì¼~T+7) ìˆ˜ì£¼ëŸ‰ ì˜ˆì¸¡
         - 0 ë°ì´í„° ì‚­ì œ ì—†ì´ í•™ìŠµ (0ì„ ì •ë³´ë¡œ í™œìš©)
         - MinMaxScaler ê¸°ë°˜ 0~1 ì •ê·œí™” (ì¤‘ì•™ê°’ â‰ˆ 0.5)
         - ì¶”ê°€ í”¼ì²˜: NoOrderFlag(0ì—¬ë¶€), ZeroRatio30(0ë¹„ìœ¨)
         - Target smoothing ì ìš©
         - MAE ê¸°ë°˜ ì†ì‹¤í•¨ìˆ˜ ì‚¬ìš©
         - MAE / MAPE / ì •í™•ë„(%) ê³„ì‚° ë° ë¡œê·¸ ì¶œë ¥
         - ìµœëŒ€ 15íšŒ ë°˜ë³µ í•™ìŠµ
         - ì •í™•ë„ ìŒìˆ˜ ë°©ì§€ (0~100% ë²”ìœ„ ì œí•œ)
         - í‰ê· ê°’ì´ ë„ˆë¬´ ì‘ì„ ê²½ìš° ì •í™•ë„ ê³„ì‚° ë³´ì •
         - MAE 40 ì´ìƒì¸ Product ìë™ ì¬í•™ìŠµ (ìµœëŒ€ 5íšŒ ë°˜ë³µ)

ì‹¤í–‰ë²• :
    1. í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œë¡œ ì´ë™
        cd ~/KAMP
    2. Python ëª¨ë“ˆ í˜•íƒœë¡œ ì‹¤í–‰
        python -m models.train_tab_a_recent90_forecast
"""

import os
import json
import numpy as np
import pandas as pd
import matplotlib
from datetime import timedelta
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error
from keras.models import Sequential
from keras.layers import Conv1D, MaxPooling1D, LSTM, Dropout, Dense
from keras.callbacks import EarlyStopping
from keras.optimizers import Adam
from keras.losses import MeanAbsoluteError as MAELoss
from keras.metrics import MeanAbsoluteError

# ê³µí†µ ì„¤ì •
from models.common import OUTPUT_DIR, DATA_RESULT_DIR

matplotlib.rc('font', family='Malgun Gothic')
matplotlib.rc('axes', unicode_minus=False)

#####################################################################
# ê²½ë¡œ ì„¤ì •
#####################################################################
DATA_PATH = os.path.join(DATA_RESULT_DIR, "04_ì „ì²˜ë¦¬_ë¶ˆí•„ìš”ì»¬ëŸ¼_ì œê±°.csv")
OUTPUT_SUBDIR = os.path.join(OUTPUT_DIR, "tab_a_recent90_forecast")
os.makedirs(OUTPUT_SUBDIR, exist_ok=True)

RESULT_PATH = os.path.join(OUTPUT_SUBDIR, "forecast_7days.csv")
ACC_JSON_PATH = os.path.join(OUTPUT_SUBDIR, "accuracy_score.json")
ACC_CSV_PATH = os.path.join(OUTPUT_SUBDIR, "accuracy_score.csv")

#####################################################################
# íŒŒë¼ë¯¸í„°
#####################################################################
SEQ_LEN = 21
PRED_DAYS = 7
EPOCHS = 200
MAX_RETRY = 5
BATCH_SIZE = 16
LEARNING_RATE = 0.0003
PATIENCE = 20
TARGET_ACCURACY = 80.0

BASE_FEATURES = [
    "Tì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰","T+1ì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰","T+2ì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰","T+3ì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰","T+4ì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰",
    "ì‘ë…„ Tì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰","ì‘ë…„ T+1ì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰","ì‘ë…„ T+2ì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰","ì‘ë…„ T+3ì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰","ì‘ë…„ T+4ì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰",
    "Temperature","Humidity"
]
TARGET_COL = "Tì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰_smooth"

#####################################################################
# ë°ì´í„° ë¡œë“œ
#####################################################################
df = pd.read_csv(DATA_PATH, encoding="utf-8-sig")
df["Date"] = pd.to_datetime(df["Date"], errors="coerce")

print(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ / ì „ì²´ í–‰: {df.shape[0]}, ì—´: {df.shape[1]}")
product_list = df["Product_Number"].unique()
print(f"ì´ Product_Number ê°œìˆ˜: {len(product_list)}")

#####################################################################
# ëª¨ë¸ ì •ì˜
#####################################################################
def build_model(input_shape, pred_days):
    model = Sequential([
        Conv1D(128, kernel_size=3, activation='relu', input_shape=input_shape),
        Conv1D(128, kernel_size=3, activation='relu'),
        MaxPooling1D(pool_size=2),
        LSTM(128, return_sequences=True),
        LSTM(64, return_sequences=True),
        Dropout(0.1),
        LSTM(32, return_sequences=False),
        Dense(128, activation='relu'),
        Dense(64, activation='relu'),
        Dense(32, activation='relu'),
        Dense(pred_days)
    ])
    model.compile(
        optimizer=Adam(learning_rate=LEARNING_RATE),
        loss=MAELoss(),
        metrics=[MeanAbsoluteError()]
    )
    return model

#####################################################################
# ê²°ê³¼ êµ¬ì¡°
#####################################################################
forecast_all = pd.DataFrame()
accuracy_records = []

#####################################################################
# Product ë³„ í•™ìŠµ
#####################################################################
for product in product_list:
    product_df = df[df["Product_Number"] == product].sort_values("Date").reset_index(drop=True)
    if product_df.shape[0] < 90:
        print(f"[{product}] ë°ì´í„° ë¶€ì¡± ({product_df.shape[0]}í–‰) â†’ ìŠ¤í‚µ")
        continue

    latest_date = product_df["Date"].max()
    cutoff_date = latest_date - timedelta(days=90)
    recent_df = product_df[product_df["Date"] >= cutoff_date].reset_index(drop=True)

    # 0ê°’ ê·¸ëŒ€ë¡œ ìœ ì§€
    recent_df["NoOrderFlag"] = (recent_df["Tì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰"] == 0).astype(int)
    recent_df["ZeroRatio30"] = (
        recent_df["Tì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰"].rolling(window=30, min_periods=1)
        .apply(lambda x: (x == 0).sum() / len(x))
        .fillna(0)
    )

    # Target smoothing
    recent_df["Tì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰_smooth"] = (
        recent_df["Tì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰"].rolling(window=3, min_periods=1).mean()
    )

    # Î” í”¼ì²˜ ì¶”ê°€
    for shift in range(1, 5):
        recent_df[f"Î”T+{shift}"] = recent_df[f"T+{shift}ì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰"] - recent_df["Tì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰"]

    FEATURE_COLS = BASE_FEATURES + [f"Î”T+{i}" for i in range(1, 5)] + ["NoOrderFlag", "ZeroRatio30"]

    # âœ… MinMaxScaler ì ìš©
    scaler_feature = MinMaxScaler(feature_range=(0, 1))
    scaler_target = MinMaxScaler(feature_range=(0, 1))
    scaler_feature.fit(recent_df[FEATURE_COLS])
    scaler_target.fit(recent_df[[TARGET_COL]])

    scaled_features = scaler_feature.transform(recent_df[FEATURE_COLS])
    scaled_target = scaler_target.transform(recent_df[[TARGET_COL]])

    scaled_df = pd.DataFrame(scaled_features, columns=FEATURE_COLS)
    scaled_df["TARGET"] = scaled_target

    # ì‹œí€€ìŠ¤ êµ¬ì„±
    X, y = [], []
    for i in range(len(scaled_df) - SEQ_LEN - PRED_DAYS):
        X.append(scaled_df.iloc[i:i+SEQ_LEN][FEATURE_COLS].values)
        y.append(scaled_df.iloc[i+SEQ_LEN:i+SEQ_LEN+PRED_DAYS]["TARGET"].values)
    X, y = np.array(X), np.array(y)

    if len(X) == 0:
        print(f"[{product}] ì‹œí€€ìŠ¤ ìƒì„± ë¶ˆê°€ â†’ ìŠ¤í‚µ")
        continue

    split_index = int(len(X) * 0.8)
    X_train, X_val = X[:split_index], X[split_index:]
    y_train, y_val = y[:split_index], y[split_index:]

    model = build_model((SEQ_LEN, len(FEATURE_COLS)), PRED_DAYS)
    callbacks = [EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True)]

    best_accuracy = 0
    mae_val = mape_val = None

    for retry in range(1, MAX_RETRY + 1):
        print(f"\n[{product}] í•™ìŠµ ì‹œë„ {retry}/{MAX_RETRY}")
        model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=EPOCHS,
            batch_size=BATCH_SIZE,
            callbacks=callbacks,
            verbose=0
        )

        val_pred = model.predict(X_val, verbose=0)
        val_pred_restored = scaler_target.inverse_transform(val_pred.flatten().reshape(-1, 1)).flatten()
        y_val_restored = scaler_target.inverse_transform(y_val.flatten().reshape(-1, 1)).flatten()

        mae_val = mean_absolute_error(y_val_restored, val_pred_restored)
        mape_val = np.mean(np.abs((y_val_restored - val_pred_restored) / np.clip(y_val_restored, 1e-5, None))) * 100

        mean_actual = max(np.mean(y_val_restored), 10)
        accuracy = 100 - (mae_val / mean_actual * 100)
        accuracy = max(0, min(accuracy, 100))

        if accuracy > best_accuracy:
            best_accuracy = accuracy

        print(f"[{product}] MAE: {mae_val:.2f} | MAPE: {mape_val:.2f}% | ì •í™•ë„: {accuracy:.2f}%")

        if best_accuracy >= TARGET_ACCURACY:
            print(f"[{product}] ëª©í‘œ ì •í™•ë„ ë„ë‹¬ ({best_accuracy:.2f}%) â†’ ì¡°ê¸° ì¢…ë£Œ")
            break

    print(f"[{product}] ìµœì¢… ê²°ê³¼ â†’ MAE: {mae_val:.4f}, MAPE: {mape_val:.2f}%, ì •í™•ë„: {best_accuracy:.2f}%")

    accuracy_records.append({
        "Product_Number": product,
        "MAE": round(float(mae_val), 4),
        "MAPE(%)": round(float(mape_val), 2),
        "Accuracy(%)": round(float(best_accuracy), 2)
    })

#####################################################################
# ê²°ê³¼ ì €ì¥ ë° ìš”ì•½ ì¶œë ¥
#####################################################################
pd.DataFrame(accuracy_records).to_csv(ACC_CSV_PATH, index=False, encoding="utf-8-sig")
with open(ACC_JSON_PATH, "w", encoding="utf-8") as jf:
    json.dump(accuracy_records, jf, ensure_ascii=False, indent=4)

print("\n================== í•™ìŠµ ê²°ê³¼ ìš”ì•½ ==================")
print("{:<15} {:>10} {:>12} {:>12}".format("Product_Number", "MAE", "MAPE(%)", "Accuracy(%)"))
print("-------------------------------------------------------------")

for r in accuracy_records:
    print("{:<15} {:>10.4f} {:>12.2f} {:>12.2f}".format(
        r["Product_Number"], r["MAE"], r["MAPE(%)"], r["Accuracy(%)"]
    ))

print("=============================================================\n")

# ì „ì²´ í‰ê·  ê³„ì‚°
mean_mae = np.mean([r["MAE"] for r in accuracy_records])
mean_mape = np.mean([r["MAPE(%)"] for r in accuracy_records])
mean_acc = np.mean([r["Accuracy(%)"] for r in accuracy_records])

print("ğŸ“Š [ì „ì²´ í‰ê·  ì„±ëŠ¥ ìš”ì•½]")
print(f"MAE í‰ê·      : {mean_mae:.4f}")
print(f"MAPE í‰ê· (%) : {mean_mape:.2f}%")
print(f"ì •í™•ë„ í‰ê· (%) : {mean_acc:.2f}%")
print("=============================================================\n")

summary = {
    "Product_Number": "ì „ì²´ í‰ê· ",
    "MAE": round(mean_mae, 4),
    "MAPE(%)": round(mean_mape, 2),
    "Accuracy(%)": round(mean_acc, 2)
}

accuracy_records.insert(0, summary)
pd.DataFrame(accuracy_records).to_csv(ACC_CSV_PATH, index=False, encoding="utf-8-sig")
with open(ACC_JSON_PATH, "w", encoding="utf-8") as jf:
    json.dump(accuracy_records, jf, ensure_ascii=False, indent=4)

print("âœ… ì „ì²´ ê²°ê³¼ ë° í‰ê·  ì €ì¥ ì™„ë£Œ.")
