"""
파일명 : train_tab_a_recent90_forecast.py
설명   : Product_Number별 최근 90일 데이터를 기반으로 7일치(T일+1~T+7) 수주량 예측
         (3층 LSTM 구조 + 작년 대비 비교 + 정확도 산출)
실행법 :
    - 1. 프로젝트 루트로 이동 : ~/KAMP
    - 2. 명령어 실행          : python -m models.train_tab_a_recent90_forecast
"""

import os
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
from datetime import timedelta
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error
from keras.models import Sequential
from keras.layers import Conv1D, MaxPooling1D, LSTM, Dropout, Dense
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.optimizers import Adam
from keras.losses import MeanSquaredError
from keras.metrics import MeanAbsoluteError

# 공통 설정 파일
from models.common import OUTPUT_DIR, DATA_RESULT_DIR

# ✅ 한글 폰트 설정
matplotlib.rc('font', family='Malgun Gothic')
matplotlib.rc('axes', unicode_minus=False)

#####################################################################
# 경로 세팅
#####################################################################
DATA_PATH = os.path.join(DATA_RESULT_DIR, "04_전처리_불필요컬럼_제거.csv")
OUTPUT_SUBDIR = os.path.join(OUTPUT_DIR, "tab_a_recent90_forecast")
os.makedirs(OUTPUT_SUBDIR, exist_ok=True)

RESULT_PATH = os.path.join(OUTPUT_SUBDIR, "forecast_7days.csv")
ACC_PATH = os.path.join(OUTPUT_SUBDIR, "accuracy_score.json")

#####################################################################
# 데이터 로드
#####################################################################
df = pd.read_csv(DATA_PATH, encoding="utf-8-sig")
df["Date"] = pd.to_datetime(df["Date"], errors="coerce")

print(f"데이터 로드 완료 / 전체 행: {df.shape[0]}, 열: {df.shape[1]}")
product_list = df["Product_Number"].unique()
print(f"총 Product_Number 개수: {len(product_list)}")

#####################################################################
# 파라미터 설정
#####################################################################
SEQ_LEN = 21
PRED_DAYS = 7
EPOCHS = 200
BATCH_SIZE = 16
LEARNING_RATE = 0.0005
PATIENCE = 20

FEATURE_COLS = [
    "T일 예정 수주량","T+1일 예정 수주량","T+2일 예정 수주량","T+3일 예정 수주량","T+4일 예정 수주량",
    "작년 T일 예정 수주량","작년 T+1일 예정 수주량","작년 T+2일 예정 수주량","작년 T+3일 예정 수주량","작년 T+4일 예정 수주량",
    "Temperature","Humidity"
]
TARGET_COL = "T일 예정 수주량"

#####################################################################
# 전체 결과 저장용 DataFrame
#####################################################################
forecast_all = pd.DataFrame()
mae_scores = []

#####################################################################
# Product_Number 별 반복 학습 및 예측
#####################################################################
for product in product_list:
    product_df = df[df["Product_Number"] == product].sort_values("Date").reset_index(drop=True)
    if product_df.shape[0] < 30:
        print(f"[{product}] 데이터가 너무 적어 스킵됨 ({product_df.shape[0]}행)")
        continue

    latest_date = product_df["Date"].max()
    cutoff_date = latest_date - timedelta(days=90)
    recent_df = product_df[product_df["Date"] >= cutoff_date].reset_index(drop=True)

    if recent_df.shape[0] <= SEQ_LEN + PRED_DAYS:
        print(f"[{product}] 최근 90일 데이터가 부족해 스킵됨")
        continue

    scaler_feature = MinMaxScaler()
    scaler_target = MinMaxScaler()

    scaler_feature.fit(product_df[FEATURE_COLS])
    scaler_target.fit(product_df[[TARGET_COL]])

    scaled_features = scaler_feature.transform(recent_df[FEATURE_COLS])
    scaled_target = scaler_target.transform(recent_df[[TARGET_COL]])

    scaled_df = pd.DataFrame(scaled_features, columns=FEATURE_COLS)
    scaled_df["TARGET"] = scaled_target

    X, y = [], []
    for i in range(len(scaled_df) - SEQ_LEN - PRED_DAYS):
        X.append(scaled_df.iloc[i:i+SEQ_LEN][FEATURE_COLS].values)
        y.append(scaled_df.iloc[i+SEQ_LEN:i+SEQ_LEN+PRED_DAYS]["TARGET"].values)
    X, y = np.array(X), np.array(y)

    split_index = int(len(X) * 0.8)
    X_train, X_val = X[:split_index], X[split_index:]
    y_train, y_val = y[:split_index], y[split_index:]

    model = Sequential([
        Conv1D(64, kernel_size=3, activation='relu', input_shape=(SEQ_LEN, len(FEATURE_COLS))),
        Conv1D(64, kernel_size=3, activation='relu'),
        MaxPooling1D(pool_size=2),
        LSTM(128, return_sequences=True),
        LSTM(64, return_sequences=True),
        Dropout(0.2),
        LSTM(32, return_sequences=False),
        Dense(128, activation='relu'),
        Dense(64, activation='relu'),
        Dense(PRED_DAYS)
    ])

    model.compile(
        optimizer=Adam(learning_rate=LEARNING_RATE),
        loss=MeanSquaredError(),
        metrics=[MeanAbsoluteError()]
    )

    callbacks = [
        EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True)
    ]

    print(f"\n[{product}] CNN-LSTM 학습 시작 ({recent_df.shape[0]}행)...")
    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=EPOCHS,
        batch_size=BATCH_SIZE,
        callbacks=callbacks,
        verbose=0
    )

    val_pred = model.predict(X_val)
    val_pred_restored = scaler_target.inverse_transform(val_pred.flatten().reshape(-1, 1)).flatten()
    y_val_restored = scaler_target.inverse_transform(y_val.flatten().reshape(-1, 1)).flatten()
    mae_restored = mean_absolute_error(y_val_restored, val_pred_restored)
    mae_scores.append(mae_restored)

    last_seq = scaled_df.iloc[-SEQ_LEN:][FEATURE_COLS].values.reshape(1, SEQ_LEN, len(FEATURE_COLS))
    pred_scaled = model.predict(last_seq)
    pred_restored = scaler_target.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()

    future_dates = [latest_date + timedelta(days=i+1) for i in range(PRED_DAYS)]

    compare_df = pd.DataFrame({
        "Product_Number": product,
        "Date": future_dates,
        "Predicted_T일_수주량": pred_restored
    })

    # 작년 동일 날짜 비교
    for idx, row in compare_df.iterrows():
        last_year_date = row["Date"] - timedelta(days=365)
        prev_data = product_df[product_df["Date"] == last_year_date]
        if not prev_data.empty:
            compare_df.loc[idx, "작년_T일_예정수주량"] = prev_data.iloc[0]["작년 T일 예정 수주량"]
            diff = row["Predicted_T일_수주량"] - compare_df.loc[idx, "작년_T일_예정수주량"]
            compare_df.loc[idx, "증감율(%)"] = round((diff / compare_df.loc[idx, "작년_T일_예정수주량"]) * 100, 2)
        else:
            compare_df.loc[idx, "작년_T일_예정수주량"] = np.nan
            compare_df.loc[idx, "증감율(%)"] = np.nan

    forecast_all = pd.concat([forecast_all, compare_df], ignore_index=True)
    print(f"[{product}] 예측 완료 / MAE: {mae_restored:.4f}")

#####################################################################
# 전체 결과 저장
#####################################################################
forecast_all.to_csv(RESULT_PATH, index=False, encoding="utf-8-sig")
print(f"\n모든 Product_Number 예측 결과 저장 완료 : {RESULT_PATH}")

#####################################################################
# 전체 정확도 계산
#####################################################################
if mae_scores:
    mean_mae = np.mean(mae_scores)
    mean_actual = np.mean(df["T일 예정 수주량"])
    accuracy_score = 100 - (mean_mae / mean_actual * 100)
    accuracy_info = {
        "Mean_MAE": round(float(mean_mae), 4),
        "Mean_Actual": round(float(mean_actual), 4),
        "Accuracy(%)": round(float(accuracy_score), 2)
    }
    with open(ACC_PATH, "w", encoding="utf-8") as f:
        json.dump(accuracy_info, f, ensure_ascii=False, indent=4)
    print(f"정확도 계산 완료 : {accuracy_info}")
else:
    print("MAE 점수를 계산할 수 없습니다 (데이터 부족).")

print("\n✅ Product_Number별 최신 90일 기반 7일 예측 + 작년 대비 비교 + 정확도 산출 완료 (tab_a_recent90_forecast)")
